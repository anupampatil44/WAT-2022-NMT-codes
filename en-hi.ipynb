{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### If you dont want to use Wandb, disable Wandb otherwise optional\n\nreferences for WANDB\nhttps://analyticsindiamag.com/hands-on-guide-to-weights-and-biases-wandb-with-python-implementation/\n\nhttps://docs.wandb.ai/\n","metadata":{"id":"cV-pf35571ap"}},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"]=\"true\"","metadata":{"id":"tmYJBBbwyiX3","execution":{"iopub.status.busy":"2022-07-10T11:10:03.392905Z","iopub.execute_input":"2022-07-10T11:10:03.393501Z","iopub.status.idle":"2022-07-10T11:10:03.422362Z","shell.execute_reply.started":"2022-07-10T11:10:03.393371Z","shell.execute_reply":"2022-07-10T11:10:03.421392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install required packages","metadata":{"id":"k1hOFHi-x5UZ"}},{"cell_type":"code","source":"! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]","metadata":{"id":"SqADZ2Sgx5Ua","outputId":"60c95827-a686-45eb-c201-e23bc8b03b2b","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T11:35:38.551726Z","iopub.execute_input":"2022-07-10T11:35:38.552407Z","iopub.status.idle":"2022-07-10T11:35:55.698742Z","shell.execute_reply.started":"2022-07-10T11:35:38.552285Z","shell.execute_reply":"2022-07-10T11:35:55.697397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version","metadata":{"id":"qN5RtJdM8xi5"}},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"id":"5xKFwtNEx5Uc","outputId":"1206f370-b7a8-4a34-bc6d-36f1a731be6a","execution":{"iopub.status.busy":"2022-07-10T11:35:55.702810Z","iopub.execute_input":"2022-07-10T11:35:55.703526Z","iopub.status.idle":"2022-07-10T11:36:03.049297Z","shell.execute_reply.started":"2022-07-10T11:35:55.703476Z","shell.execute_reply":"2022-07-10T11:36:03.047705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\"","metadata":{"id":"MX7DsEmOx5Ud","execution":{"iopub.status.busy":"2022-07-10T11:36:46.364349Z","iopub.execute_input":"2022-07-10T11:36:46.365053Z","iopub.status.idle":"2022-07-10T11:36:46.371278Z","shell.execute_reply.started":"2022-07-10T11:36:46.365019Z","shell.execute_reply":"2022-07-10T11:36:46.369982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"agDlgrOix5Uj","outputId":"d52e9acb-10d0-464f-c9f1-1947b7a7b0e6","execution":{"iopub.status.busy":"2022-07-10T11:36:48.514996Z","iopub.execute_input":"2022-07-10T11:36:48.515380Z","iopub.status.idle":"2022-07-10T11:36:57.246022Z","shell.execute_reply.started":"2022-07-10T11:36:48.515341Z","shell.execute_reply":"2022-07-10T11:36:57.244732Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can directly call this tokenizer on one sentence or a pair of sentences:","metadata":{"id":"zbih6yhKG9JB"}},{"cell_type":"code","source":"tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])","metadata":{"id":"j9XTBM27x5Uk","outputId":"2bd42d79-8437-41b1-e1b4-80723a18f614","execution":{"iopub.status.busy":"2022-06-26T18:11:30.954675Z","iopub.execute_input":"2022-06-26T18:11:30.955143Z","iopub.status.idle":"2022-06-26T18:11:30.96901Z","shell.execute_reply.started":"2022-06-26T18:11:30.955062Z","shell.execute_reply":"2022-06-26T18:11:30.967893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To prepare the targets for our model, we need to tokenize them inside the as_target_tokenizer context manager. This will make sure the tokenizer uses the special tokens corresponding to the targets:","metadata":{"id":"Lf2HfvKdHCeS"}},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))","metadata":{"id":"qvYg6BXJx5Ul","outputId":"06d8f836-7a16-4fdc-a23e-9d0973135a55","execution":{"iopub.status.busy":"2022-07-10T09:59:17.358867Z","iopub.execute_input":"2022-07-10T09:59:17.359299Z","iopub.status.idle":"2022-07-10T09:59:17.367752Z","shell.execute_reply.started":"2022-07-10T09:59:17.359262Z","shell.execute_reply":"2022-07-10T09:59:17.366725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can then write the function that will preprocess our samples. We just feed them to the tokenizer with the argument truncation=True. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset.","metadata":{"id":"AgjkiP5wHNc0"}},{"cell_type":"code","source":"prefix = \"\"\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"eng\"\ntarget_lang = \"hi\"\ndef preprocess_function(examples):\n    inputs = [prefix + ex for ex in examples[source_lang].tolist()]\n    targets = [ex for ex in examples[target_lang].tolist()]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding=True)\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True,padding=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"e1fnOpO6x5Um","execution":{"iopub.status.busy":"2022-07-10T11:38:43.162387Z","iopub.execute_input":"2022-07-10T11:38:43.163051Z","iopub.status.idle":"2022-07-10T11:38:43.172685Z","shell.execute_reply.started":"2022-07-10T11:38:43.163019Z","shell.execute_reply":"2022-07-10T11:38:43.171247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncols=['image_id', 'X', 'Y', 'Width','Height','eng','hi']\ntrain_df=pd.read_csv('../input/wat-2022-shared-task-image-captioning-task/hindi-visual-genome-train.txt',sep=\"\t\",names=cols, header=None)\ndev_df=pd.read_csv('../input/wat-2022-shared-task-image-captioning-task/hindi-visual-genome-dev.txt',sep=\"\t\",names=cols, header=None)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:38:31.268418Z","iopub.execute_input":"2022-07-10T11:38:31.269044Z","iopub.status.idle":"2022-07-10T11:38:31.475000Z","shell.execute_reply.started":"2022-07-10T11:38:31.268996Z","shell.execute_reply":"2022-07-10T11:38:31.473626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokenized_datasets = preprocess_function(train_df)#raw_datasets.map(preprocess_function, batched=True)\n\ndev_tokenized_datasets = preprocess_function(dev_df)","metadata":{"id":"uZlsJFZnx5Uo","outputId":"e39c565b-e6cb-489b-a5ca-a565624b89cf","execution":{"iopub.status.busy":"2022-07-10T11:38:45.875890Z","iopub.execute_input":"2022-07-10T11:38:45.876509Z","iopub.status.idle":"2022-07-10T11:38:53.377507Z","shell.execute_reply.started":"2022-07-10T11:38:45.876478Z","shell.execute_reply":"2022-07-10T11:38:53.376071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine-tuning the model","metadata":{"id":"b4kA3jpsHcFE"}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"id":"IvrIjd-Lx5Uq","outputId":"07457f36-49c9-419d-b0cc-dbe8429c401a","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T11:38:57.958246Z","iopub.execute_input":"2022-07-10T11:38:57.958679Z","iopub.status.idle":"2022-07-10T11:39:15.312371Z","shell.execute_reply.started":"2022-07-10T11:38:57.958648Z","shell.execute_reply":"2022-07-10T11:39:15.311036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nmodel_name = model_checkpoint.split(\"/\")[-1]\nsource_lang = \"en\"\ntarget_lang = \"hi\"\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=30,\n    predict_with_generate=True    \n)","metadata":{"id":"qk2p1KEwx5Ur","outputId":"28118e90-17a6-460a-8694-3b50cc6660c5","execution":{"iopub.status.busy":"2022-07-10T11:40:18.889296Z","iopub.execute_input":"2022-07-10T11:40:18.889750Z","iopub.status.idle":"2022-07-10T11:40:18.904167Z","shell.execute_reply.started":"2022-07-10T11:40:18.889717Z","shell.execute_reply":"2022-07-10T11:40:18.902590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"qV9wfuvZx5Us","execution":{"iopub.status.busy":"2022-07-10T11:40:21.847636Z","iopub.execute_input":"2022-07-10T11:40:21.848041Z","iopub.status.idle":"2022-07-10T11:40:21.855004Z","shell.execute_reply.started":"2022-07-10T11:40:21.848009Z","shell.execute_reply":"2022-07-10T11:40:21.853106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last thing to define for our Seq2SeqTrainer is how to compute the metrics from the predictions. We need to define a function for this, which will just use the metric we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:","metadata":{"id":"Jw7by60eH_p5"}},{"cell_type":"code","source":"from datasets import  load_metric\nmetric = load_metric(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:39:52.842137Z","iopub.execute_input":"2022-07-10T11:39:52.842847Z","iopub.status.idle":"2022-07-10T11:39:54.969611Z","shell.execute_reply.started":"2022-07-10T11:39:52.842799Z","shell.execute_reply":"2022-07-10T11:39:54.967922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"id":"mHqp_FFhx5Uu","execution":{"iopub.status.busy":"2022-07-10T11:39:56.530198Z","iopub.execute_input":"2022-07-10T11:39:56.530625Z","iopub.status.idle":"2022-07-10T11:39:56.543477Z","shell.execute_reply.started":"2022-07-10T11:39:56.530565Z","shell.execute_reply":"2022-07-10T11:39:56.541799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we just need to pass all of this along with our datasets to the Seq2SeqTrainer:","metadata":{"id":"E_XK7px-IDkC"}},{"cell_type":"code","source":"prefix = \"\"\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"eng\"\ntarget_lang = \"ml\"\ndef preprocess_function(examples):\n    inputs = [prefix + ex for ex in examples[source_lang].tolist()]\n    targets = [ex for ex in examples[target_lang].tolist()]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding=True)\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True,padding=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:40:24.555664Z","iopub.execute_input":"2022-07-10T11:40:24.556282Z","iopub.status.idle":"2022-07-10T11:40:24.572412Z","shell.execute_reply.started":"2022-07-10T11:40:24.556231Z","shell.execute_reply":"2022-07-10T11:40:24.570955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nclass ModelDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, targets):\n        self.inputs = inputs\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, index):\n#         print(\"index in getitem:\",index)\n        index=int(index)\n        input_ids = torch.tensor(self.inputs[index]).squeeze()\n        target_ids = torch.tensor(self.targets[index]).squeeze()\n        \n        return {\"input_ids\": input_ids, \"labels\": target_ids}","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:40:25.865867Z","iopub.execute_input":"2022-07-10T11:40:25.866513Z","iopub.status.idle":"2022-07-10T11:40:25.879657Z","shell.execute_reply.started":"2022-07-10T11:40:25.866461Z","shell.execute_reply":"2022-07-10T11:40:25.877960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindata=ModelDataset(train_tokenized_datasets['input_ids'],train_tokenized_datasets['labels'])\ndevdata=ModelDataset(dev_tokenized_datasets['input_ids'],dev_tokenized_datasets['labels'])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:40:02.231945Z","iopub.execute_input":"2022-07-10T11:40:02.232369Z","iopub.status.idle":"2022-07-10T11:40:02.239184Z","shell.execute_reply.started":"2022-07-10T11:40:02.232338Z","shell.execute_reply":"2022-07-10T11:40:02.237401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=traindata,\n    eval_dataset=devdata,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# trained for a total of 20 epochs","metadata":{"id":"c7zuF8rLx5Uy","execution":{"iopub.status.busy":"2022-07-10T11:40:28.199370Z","iopub.execute_input":"2022-07-10T11:40:28.200021Z","iopub.status.idle":"2022-07-10T11:40:28.217188Z","shell.execute_reply.started":"2022-07-10T11:40:28.199988Z","shell.execute_reply":"2022-07-10T11:40:28.215699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now finetune our model by just calling the train method:","metadata":{"id":"W1TskjmQIGKd"}},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"sonIRAfDx5Uz","outputId":"8a0bc390-6900-424c-f92e-e3a841ead986","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T11:40:30.467187Z","iopub.execute_input":"2022-07-10T11:40:30.467624Z","iopub.status.idle":"2022-07-10T13:21:20.830866Z","shell.execute_reply.started":"2022-07-10T11:40:30.467586Z","shell.execute_reply":"2022-07-10T13:21:20.829437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n# model.to('cpu')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T10:51:49.90049Z","iopub.execute_input":"2022-07-03T10:51:49.90114Z","iopub.status.idle":"2022-07-03T10:51:49.906886Z","shell.execute_reply.started":"2022-07-03T10:51:49.901097Z","shell.execute_reply":"2022-07-03T10:51:49.905707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nch=pd.read_csv(\"../input/wat-2022-shared-task-image-captioning-task/hindi-visual-genome-challenge-test-set.txt\",names=['image_id', 'X', 'Y', 'Width','Height','eng','hi'],sep=\"\t\",header=None)\nch","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-07-10T13:24:13.082966Z","iopub.execute_input":"2022-07-10T13:24:13.084714Z","iopub.status.idle":"2022-07-10T13:24:13.169792Z","shell.execute_reply.started":"2022-07-10T13:24:13.084667Z","shell.execute_reply":"2022-07-10T13:24:13.166611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_ch=ch['eng'].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:24:22.921463Z","iopub.execute_input":"2022-07-10T13:24:22.921922Z","iopub.status.idle":"2022-07-10T13:24:22.930145Z","shell.execute_reply.started":"2022-07-10T13:24:22.921891Z","shell.execute_reply":"2022-07-10T13:24:22.928740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(inp_ch)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T13:24:25.012540Z","iopub.execute_input":"2022-07-10T13:24:25.013138Z","iopub.status.idle":"2022-07-10T13:24:25.024810Z","shell.execute_reply.started":"2022-07-10T13:24:25.013098Z","shell.execute_reply":"2022-07-10T13:24:25.023409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:24:27.902881Z","iopub.execute_input":"2022-07-10T13:24:27.903242Z","iopub.status.idle":"2022-07-10T13:24:27.920245Z","shell.execute_reply.started":"2022-07-10T13:24:27.903212Z","shell.execute_reply":"2022-07-10T13:24:27.918756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(0)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T13:24:32.710999Z","iopub.execute_input":"2022-07-10T13:24:32.711411Z","iopub.status.idle":"2022-07-10T13:24:32.736854Z","shell.execute_reply.started":"2022-07-10T13:24:32.711363Z","shell.execute_reply":"2022-07-10T13:24:32.735578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda\ncuda.select_device(0)\ncuda.close()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T10:43:05.107818Z","iopub.execute_input":"2022-07-03T10:43:05.10872Z","iopub.status.idle":"2022-07-03T10:43:05.446121Z","shell.execute_reply.started":"2022-07-03T10:43:05.108681Z","shell.execute_reply":"2022-07-03T10:43:05.445172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-07-03T10:44:58.535203Z","iopub.execute_input":"2022-07-03T10:44:58.535792Z","iopub.status.idle":"2022-07-03T10:44:59.283423Z","shell.execute_reply.started":"2022-07-03T10:44:58.535755Z","shell.execute_reply":"2022-07-03T10:44:59.282311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = MarianMTModel.from_pretrained(model_name)\n# src_text = ['silver car is parked']\n# src.\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ninf_model=AutoModelForSeq2SeqLM.from_pretrained('./opus-mt-en-hi-finetuned-en-to-hi/checkpoint-27000')\nopf=open(\"ch_op.txt\",\"a\")\nfor i in range(len(inp_ch)):\n    print(i)\n    translated = inf_model.generate(**tokenizer([inp_ch[i]], return_tensors=\"pt\", padding=True))\n    op=[tokenizer.decode(t, skip_special_tokens=True) for t in translated][0]\n    opf.write(str(op)+'\\n')\n    \nopf.close()","metadata":{"id":"4h_jIFZgx5U2","outputId":"77d69535-6d1e-486b-df14-382718414698","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T13:25:39.050312Z","iopub.execute_input":"2022-07-10T13:25:39.051222Z","iopub.status.idle":"2022-07-10T13:37:55.807620Z","shell.execute_reply.started":"2022-07-10T13:25:39.051167Z","shell.execute_reply":"2022-07-10T13:37:55.806471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"te","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:06:31.511356Z","iopub.execute_input":"2022-07-10T14:06:31.511802Z","iopub.status.idle":"2022-07-10T14:06:31.539108Z","shell.execute_reply.started":"2022-07-10T14:06:31.511769Z","shell.execute_reply":"2022-07-10T14:06:31.537424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nte=pd.read_csv(\"../input/wat-2022-shared-task-image-captioning-task/hindi-visual-genome-test.txt\",names=['image_id', 'X', 'Y', 'Width','Height','eng','hi'],sep=\"\t\",header=None)\ntlist=te['eng'].tolist()\n\nopf=open(\"hi_test_op.txt\",\"w\")\nfor i in range(len(tlist)):\n    print(i)\n    translated = inf_model.generate(**tokenizer([tlist[i]], return_tensors=\"pt\", padding=True))\n    op=[tokenizer.decode(t, skip_special_tokens=True) for t in translated][0]\n    opf.write(str(op)+'\\n')\n    \nopf.close()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T14:41:24.499414Z","iopub.execute_input":"2022-07-10T14:41:24.500503Z","iopub.status.idle":"2022-07-10T14:54:14.120998Z","shell.execute_reply.started":"2022-07-10T14:41:24.500455Z","shell.execute_reply":"2022-07-10T14:54:14.119487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=\"A rectangular picture on a yellow wall.\"\n\ntranslated = inf_model.generate(**tokenizer([s], return_tensors=\"pt\", padding=True))\nop=[tokenizer.decode(t, skip_special_tokens=True) for t in translated][0]\nprint(op)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:01:54.739686Z","iopub.execute_input":"2022-07-10T11:01:54.740355Z","iopub.status.idle":"2022-07-10T11:01:55.118400Z","shell.execute_reply.started":"2022-07-10T11:01:54.740318Z","shell.execute_reply":"2022-07-10T11:01:55.117297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}