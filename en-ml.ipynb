{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"]=\"true\"","metadata":{"id":"tmYJBBbwyiX3","execution":{"iopub.status.busy":"2022-07-10T09:58:36.815690Z","iopub.execute_input":"2022-07-10T09:58:36.817015Z","iopub.status.idle":"2022-07-10T09:58:36.848986Z","shell.execute_reply.started":"2022-07-10T09:58:36.816898Z","shell.execute_reply":"2022-07-10T09:58:36.847763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install required packages","metadata":{"id":"k1hOFHi-x5UZ"}},{"cell_type":"code","source":"! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]","metadata":{"id":"SqADZ2Sgx5Ua","outputId":"60c95827-a686-45eb-c201-e23bc8b03b2b","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T09:58:38.680224Z","iopub.execute_input":"2022-07-10T09:58:38.680710Z","iopub.status.idle":"2022-07-10T09:58:51.250201Z","shell.execute_reply.started":"2022-07-10T09:58:38.680662Z","shell.execute_reply":"2022-07-10T09:58:51.249099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"id":"5xKFwtNEx5Uc","outputId":"1206f370-b7a8-4a34-bc6d-36f1a731be6a","execution":{"iopub.status.busy":"2022-07-10T09:58:52.678521Z","iopub.execute_input":"2022-07-10T09:58:52.678887Z","iopub.status.idle":"2022-07-10T09:58:58.545432Z","shell.execute_reply.started":"2022-07-10T09:58:52.678855Z","shell.execute_reply":"2022-07-10T09:58:58.543523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuning a model on a translation task","metadata":{"id":"DKkJGYY19I11"}},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-ml\"","metadata":{"id":"MX7DsEmOx5Ud","execution":{"iopub.status.busy":"2022-07-10T09:59:05.601743Z","iopub.execute_input":"2022-07-10T09:59:05.602604Z","iopub.status.idle":"2022-07-10T09:59:05.606992Z","shell.execute_reply.started":"2022-07-10T09:59:05.602566Z","shell.execute_reply":"2022-07-10T09:59:05.605761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"agDlgrOix5Uj","outputId":"d52e9acb-10d0-464f-c9f1-1947b7a7b0e6","execution":{"iopub.status.busy":"2022-07-10T09:59:07.606479Z","iopub.execute_input":"2022-07-10T09:59:07.606830Z","iopub.status.idle":"2022-07-10T09:59:14.201109Z","shell.execute_reply.started":"2022-07-10T09:59:07.606786Z","shell.execute_reply":"2022-07-10T09:59:14.200191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can directly call this tokenizer on one sentence or a pair of sentences:","metadata":{"id":"zbih6yhKG9JB"}},{"cell_type":"code","source":"tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])","metadata":{"id":"j9XTBM27x5Uk","outputId":"2bd42d79-8437-41b1-e1b4-80723a18f614","execution":{"iopub.status.busy":"2022-06-26T18:11:30.954675Z","iopub.execute_input":"2022-06-26T18:11:30.955143Z","iopub.status.idle":"2022-06-26T18:11:30.96901Z","shell.execute_reply.started":"2022-06-26T18:11:30.955062Z","shell.execute_reply":"2022-06-26T18:11:30.967893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To prepare the targets for our model, we need to tokenize them inside the as_target_tokenizer context manager. This will make sure the tokenizer uses the special tokens corresponding to the targets:","metadata":{"id":"Lf2HfvKdHCeS"}},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))","metadata":{"id":"qvYg6BXJx5Ul","outputId":"06d8f836-7a16-4fdc-a23e-9d0973135a55","execution":{"iopub.status.busy":"2022-07-10T09:59:17.358867Z","iopub.execute_input":"2022-07-10T09:59:17.359299Z","iopub.status.idle":"2022-07-10T09:59:17.367752Z","shell.execute_reply.started":"2022-07-10T09:59:17.359262Z","shell.execute_reply":"2022-07-10T09:59:17.366725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can then write the function that will preprocess our samples. We just feed them to the tokenizer with the argument truncation=True. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset.","metadata":{"id":"AgjkiP5wHNc0"}},{"cell_type":"code","source":"prefix = \"\"\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"eng\"\ntarget_lang = \"ml\"\ndef preprocess_function(examples):\n    inputs = [prefix + ex for ex in examples[source_lang].tolist()]\n    targets = [ex for ex in examples[target_lang].tolist()]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding=True)\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True,padding=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"e1fnOpO6x5Um","execution":{"iopub.status.busy":"2022-07-10T09:59:19.811710Z","iopub.execute_input":"2022-07-10T09:59:19.812141Z","iopub.status.idle":"2022-07-10T09:59:19.825981Z","shell.execute_reply.started":"2022-07-10T09:59:19.812103Z","shell.execute_reply":"2022-07-10T09:59:19.825108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncols=['image_id', 'X', 'Y', 'Width','Height','eng','ml']\ntrain_df=pd.read_csv('../input/watml/ml_dev.csv',names=cols, header=None)\ndev_df=pd.read_csv('../input/watml/ml_dev.csv',names=cols, header=None)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T10:02:21.747021Z","iopub.execute_input":"2022-07-10T10:02:21.747384Z","iopub.status.idle":"2022-07-10T10:02:21.767319Z","shell.execute_reply.started":"2022-07-10T10:02:21.747355Z","shell.execute_reply":"2022-07-10T10:02:21.766448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokenized_datasets = preprocess_function(train_df)#raw_datasets.map(preprocess_function, batched=True)\n\ndev_tokenized_datasets = preprocess_function(dev_df)","metadata":{"id":"uZlsJFZnx5Uo","outputId":"e39c565b-e6cb-489b-a5ca-a565624b89cf","execution":{"iopub.status.busy":"2022-07-10T10:02:24.263651Z","iopub.execute_input":"2022-07-10T10:02:24.264323Z","iopub.status.idle":"2022-07-10T10:02:24.577729Z","shell.execute_reply.started":"2022-07-10T10:02:24.264285Z","shell.execute_reply":"2022-07-10T10:02:24.576771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine-tuning the model","metadata":{"id":"b4kA3jpsHcFE"}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"id":"IvrIjd-Lx5Uq","outputId":"07457f36-49c9-419d-b0cc-dbe8429c401a","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T10:02:26.782063Z","iopub.execute_input":"2022-07-10T10:02:26.783123Z","iopub.status.idle":"2022-07-10T10:02:36.508311Z","shell.execute_reply.started":"2022-07-10T10:02:26.783068Z","shell.execute_reply":"2022-07-10T10:02:36.507323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nmodel_name = model_checkpoint.split(\"/\")[-1]\nsource_lang = \"en\"\ntarget_lang = \"ml\"\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=40,\n    predict_with_generate=True    \n)","metadata":{"id":"qk2p1KEwx5Ur","outputId":"28118e90-17a6-460a-8694-3b50cc6660c5","execution":{"iopub.status.busy":"2022-07-10T10:03:10.003151Z","iopub.execute_input":"2022-07-10T10:03:10.003736Z","iopub.status.idle":"2022-07-10T10:03:10.078858Z","shell.execute_reply.started":"2022-07-10T10:03:10.003704Z","shell.execute_reply":"2022-07-10T10:03:10.077892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"qV9wfuvZx5Us","execution":{"iopub.status.busy":"2022-07-10T10:03:13.042878Z","iopub.execute_input":"2022-07-10T10:03:13.043219Z","iopub.status.idle":"2022-07-10T10:03:13.048325Z","shell.execute_reply.started":"2022-07-10T10:03:13.043190Z","shell.execute_reply":"2022-07-10T10:03:13.047016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import  load_metric\nmetric = load_metric(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T10:03:15.582415Z","iopub.execute_input":"2022-07-10T10:03:15.582755Z","iopub.status.idle":"2022-07-10T10:03:16.227414Z","shell.execute_reply.started":"2022-07-10T10:03:15.582724Z","shell.execute_reply":"2022-07-10T10:03:16.226565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"id":"mHqp_FFhx5Uu","execution":{"iopub.status.busy":"2022-07-10T10:03:18.735310Z","iopub.execute_input":"2022-07-10T10:03:18.735730Z","iopub.status.idle":"2022-07-10T10:03:18.751851Z","shell.execute_reply.started":"2022-07-10T10:03:18.735693Z","shell.execute_reply":"2022-07-10T10:03:18.750560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prefix = \"\"\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"eng\"\ntarget_lang = \"ml\"\ndef preprocess_function(examples):\n    inputs = [prefix + ex for ex in examples[source_lang].tolist()]\n    targets = [ex for ex in examples[target_lang].tolist()]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding=True)\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True,padding=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2022-07-10T10:03:20.502394Z","iopub.execute_input":"2022-07-10T10:03:20.503249Z","iopub.status.idle":"2022-07-10T10:03:20.510864Z","shell.execute_reply.started":"2022-07-10T10:03:20.503200Z","shell.execute_reply":"2022-07-10T10:03:20.509853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nclass ModelDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, targets):\n        self.inputs = inputs\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, index):\n#         print(\"index in getitem:\",index)\n        index=int(index)\n        input_ids = torch.tensor(self.inputs[index]).squeeze()\n        target_ids = torch.tensor(self.targets[index]).squeeze()\n        \n        return {\"input_ids\": input_ids, \"labels\": target_ids}","metadata":{"execution":{"iopub.status.busy":"2022-07-10T10:03:24.826661Z","iopub.execute_input":"2022-07-10T10:03:24.827621Z","iopub.status.idle":"2022-07-10T10:03:24.835407Z","shell.execute_reply.started":"2022-07-10T10:03:24.827563Z","shell.execute_reply":"2022-07-10T10:03:24.834469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindata=ModelDataset(train_tokenized_datasets['input_ids'],train_tokenized_datasets['labels'])\ndevdata=ModelDataset(dev_tokenized_datasets['input_ids'],dev_tokenized_datasets['labels'])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T10:03:26.754019Z","iopub.execute_input":"2022-07-10T10:03:26.754651Z","iopub.status.idle":"2022-07-10T10:03:26.759543Z","shell.execute_reply.started":"2022-07-10T10:03:26.754615Z","shell.execute_reply":"2022-07-10T10:03:26.758465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=traindata,\n    eval_dataset=devdata,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# trained for a total of 20 epochs","metadata":{"id":"c7zuF8rLx5Uy","execution":{"iopub.status.busy":"2022-07-10T10:03:29.741600Z","iopub.execute_input":"2022-07-10T10:03:29.741960Z","iopub.status.idle":"2022-07-10T10:03:34.220524Z","shell.execute_reply.started":"2022-07-10T10:03:29.741929Z","shell.execute_reply":"2022-07-10T10:03:34.219567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now finetune our model by just calling the train method:","metadata":{"id":"W1TskjmQIGKd"}},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"sonIRAfDx5Uz","outputId":"8a0bc390-6900-424c-f92e-e3a841ead986","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T10:03:37.065749Z","iopub.execute_input":"2022-07-10T10:03:37.066417Z","iopub.status.idle":"2022-07-10T10:20:11.327648Z","shell.execute_reply.started":"2022-07-10T10:03:37.066379Z","shell.execute_reply":"2022-07-10T10:20:11.326703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\nsrc_text = ['My name is Sarah and I live in London']\n\n# model_name = 'opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000'\n# tokenizer = tokenizer.from_pretrained(model_name)\nprint(tokenizer.supported_language_codes)\n","metadata":{"id":"kByQ_vxTx5U2","outputId":"c2fef526-afee-4309-9bb5-aef945b31b56","execution":{"iopub.status.busy":"2022-07-03T11:23:28.994009Z","iopub.execute_input":"2022-07-03T11:23:28.994662Z","iopub.status.idle":"2022-07-03T11:23:29.000262Z","shell.execute_reply.started":"2022-07-03T11:23:28.994624Z","shell.execute_reply":"2022-07-03T11:23:28.999345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n# model.to('cpu')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T10:51:49.90049Z","iopub.execute_input":"2022-07-03T10:51:49.90114Z","iopub.status.idle":"2022-07-03T10:51:49.906886Z","shell.execute_reply.started":"2022-07-03T10:51:49.901097Z","shell.execute_reply":"2022-07-03T10:51:49.905707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nch=pd.read_csv(\"../input/watml/challenge_ml.csv\")\nch","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-07-10T10:26:01.190422Z","iopub.execute_input":"2022-07-10T10:26:01.190805Z","iopub.status.idle":"2022-07-10T10:26:01.228152Z","shell.execute_reply.started":"2022-07-10T10:26:01.190774Z","shell.execute_reply":"2022-07-10T10:26:01.227003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_ch=ch['en'].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T10:26:06.211786Z","iopub.execute_input":"2022-07-10T10:26:06.212372Z","iopub.status.idle":"2022-07-10T10:26:06.217732Z","shell.execute_reply.started":"2022-07-10T10:26:06.212326Z","shell.execute_reply":"2022-07-10T10:26:06.216492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(inp_ch)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T10:38:23.037635Z","iopub.execute_input":"2022-07-03T10:38:23.038009Z","iopub.status.idle":"2022-07-03T10:38:23.045495Z","shell.execute_reply.started":"2022-07-03T10:38:23.037971Z","shell.execute_reply":"2022-07-03T10:38:23.044303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:43:13.038188Z","iopub.execute_input":"2022-07-28T11:43:13.038981Z","iopub.status.idle":"2022-07-28T11:43:15.065703Z","shell.execute_reply.started":"2022-07-28T11:43:13.038873Z","shell.execute_reply":"2022-07-28T11:43:15.064587Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model.to(0)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T10:26:14.361716Z","iopub.execute_input":"2022-07-10T10:26:14.362639Z","iopub.status.idle":"2022-07-10T10:26:14.380904Z","shell.execute_reply.started":"2022-07-10T10:26:14.362603Z","shell.execute_reply":"2022-07-10T10:26:14.380050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda\ncuda.select_device(0)\ncuda.close()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T10:43:05.107818Z","iopub.execute_input":"2022-07-03T10:43:05.10872Z","iopub.status.idle":"2022-07-03T10:43:05.446121Z","shell.execute_reply.started":"2022-07-03T10:43:05.108681Z","shell.execute_reply":"2022-07-03T10:43:05.445172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-07-03T10:44:58.535203Z","iopub.execute_input":"2022-07-03T10:44:58.535792Z","iopub.status.idle":"2022-07-03T10:44:59.283423Z","shell.execute_reply.started":"2022-07-03T10:44:58.535755Z","shell.execute_reply":"2022-07-03T10:44:59.282311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = MarianMTModel.from_pretrained(model_name)\n# src_text = ['silver car is parked']\n# src.\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ninf_model=AutoModelForSeq2SeqLM.from_pretrained('./opus-mt-en-ml-finetuned-en-to-ml/checkpoint-500')\nopf=open(\"ch_op.txt\",\"a\")\nfor i in range(len(inp_ch)):\n    print(i)\n    translated = inf_model.generate(**tokenizer([inp_ch[i]], return_tensors=\"pt\", padding=True))\n    op=[tokenizer.decode(t, skip_special_tokens=True) for t in translated][0]\n    opf.write(str(op)+'\\n')\n    \nopf.close()","metadata":{"id":"4h_jIFZgx5U2","outputId":"77d69535-6d1e-486b-df14-382718414698","scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T10:26:22.101435Z","iopub.execute_input":"2022-07-10T10:26:22.101868Z","iopub.status.idle":"2022-07-10T10:36:55.739749Z","shell.execute_reply.started":"2022-07-10T10:26:22.101813Z","shell.execute_reply":"2022-07-10T10:36:55.738796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"te","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:56:37.740337Z","iopub.execute_input":"2022-07-03T11:56:37.741084Z","iopub.status.idle":"2022-07-03T11:56:37.759196Z","shell.execute_reply.started":"2022-07-03T11:56:37.741047Z","shell.execute_reply":"2022-07-03T11:56:37.758069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nte=pd.read_csv(\"../input/watml/ml_test.csv\")\ntlist=te['eng'].tolist()\n\nopf=open(\"test_op.txt\",\"a\")\nfor i in range(len(tlist)):\n    print(i)\n    translated = inf_model.generate(**tokenizer([tlist[i]], return_tensors=\"pt\", padding=True))\n    op=[tokenizer.decode(t, skip_special_tokens=True) for t in translated][0]\n    opf.write(str(op)+'\\n')\n    \nopf.close()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T10:38:10.132325Z","iopub.execute_input":"2022-07-10T10:38:10.132671Z","iopub.status.idle":"2022-07-10T10:48:07.471199Z","shell.execute_reply.started":"2022-07-10T10:38:10.132643Z","shell.execute_reply":"2022-07-10T10:48:07.470229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=\"A rectangular picture on a yellow wall.\"\n\ntranslated = inf_model.generate(**tokenizer([s], return_tensors=\"pt\", padding=True))\nop=[tokenizer.decode(t, skip_special_tokens=True) for t in translated][0]\nprint(op)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:01:54.739686Z","iopub.execute_input":"2022-07-10T11:01:54.740355Z","iopub.status.idle":"2022-07-10T11:01:55.118400Z","shell.execute_reply.started":"2022-07-10T11:01:54.740318Z","shell.execute_reply":"2022-07-10T11:01:55.117297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}